services:
  dbt_chinook:
    container_name: dbt_chinook
    image: dbt_chinook_image
    restart: always
    volumes:
      - ./dbt:${CONTAINER_PROJECT_DIR}
    environment:
      - DBT_PROFILES_DIR=${CONTAINER_PROJECT_DIR}/${PROJECT_NAME}
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      - TRANSACTIONAL_SCHEMA=${TRANSACTIONAL_SCHEMA}
      - ANALYTICAL_SCHEMA=${ANALYTICAL_SCHEMA}
      - CONTAINER_PROJECT_DIR=${CONTAINER_PROJECT_DIR}
      - PROJECT_NAME=${PROJECT_NAME}
      - ROOT_CERT_PATH=${ROOT_CERT_PATH}
    networks:
      - dbt_dagster_network
    ports:
      - "8080:8080" # docs
    entrypoint: ["${CONTAINER_PROJECT_DIR}/scripts/dbt_entrypoint.sh"]

  # This service runs the postgres DB used by dagster for run storage, schedule storage,
  # and event log storage. Depending on the hardware you run this Compose on, you may be able
  # to reduce the interval and timeout in the healthcheck to speed up your `docker-compose up` times.
  dagster_postgresql:
    image: postgres:11
    container_name: dagster_postgresql
    environment:
      POSTGRES_USER: "postgres_user"
      POSTGRES_PASSWORD: "postgres_password"
      POSTGRES_DB: "postgres_db"
    networks:
      - dbt_dagster_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres_user -d postgres_db"]
      interval: 10s
      timeout: 8s
      retries: 5

  # This service runs the gRPC server that loads your user code, in both dagster-webserver
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by the
  # webserver.
  dagster_user_code:
    build:
      context: .
      dockerfile: ./Dockerfile_user_code
    container_name: dagster_user_code
    image: dagster_user_code_image
    volumes:
      - ./dbt:/opt/dagster/dbt
      - ./dagster:/opt/dagster/app
    environment:
      DAGSTER_POSTGRES_USER: "postgres_user"
      DAGSTER_POSTGRES_PASSWORD: "postgres_password"
      DAGSTER_POSTGRES_DB: "postgres_db"
      DAGSTER_CURRENT_IMAGE: "dagster_user_code_image"
      DBT_PROFILES_DIR: ${CONTAINER_PROJECT_DIR}/${PROJECT_NAME}
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      TRANSACTIONAL_SCHEMA: ${TRANSACTIONAL_SCHEMA}
      ANALYTICAL_SCHEMA: ${ANALYTICAL_SCHEMA}
      CONTAINER_PROJECT_DIR: ${CONTAINER_PROJECT_DIR}
      PROJECT_NAME: ${PROJECT_NAME}
      ROOT_CERT_PATH: ${ROOT_CERT_PATH}
    networks:
      - dbt_dagster_network

  # This service runs dagster-webserver, which loads your user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from the webserver will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  dagster_webserver:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagster-webserver
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: dagster_webserver
    restart: on-failure
    expose:
      - "3000"
    ports:
      - "3000:3000"
    environment:
      DAGSTER_POSTGRES_USER: "postgres_user"
      DAGSTER_POSTGRES_PASSWORD: "postgres_password"
      DAGSTER_POSTGRES_DB: "postgres_db"
    volumes: # Make docker client accessible so we can terminate containers from the webserver
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      - dbt_dagster_network
    depends_on:
      dagster_postgresql:
        condition: service_healthy
      dagster_user_code:
        condition: service_started

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemon:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster_daemon
    restart: on-failure
    environment:
      DAGSTER_POSTGRES_USER: "postgres_user"
      DAGSTER_POSTGRES_PASSWORD: "postgres_password"
      DAGSTER_POSTGRES_DB: "postgres_db"
    volumes: # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      - dbt_dagster_network
    depends_on:
      dagster_postgresql:
        condition: service_healthy
      dagster_user_code:
        condition: service_started

networks:
  dbt_dagster_network:
    driver: bridge
    name: dbt_dagster_network
